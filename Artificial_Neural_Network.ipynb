{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QjmNeX0Xb9v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
        "from sklearn.decomposition import PCA as sklearnPCA\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtklSQPDgHPR",
        "colab_type": "text"
      },
      "source": [
        "**Initially reading input from the dataset, splitting the input into traning and testing sets.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UCt2yKnXfaa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "b1690502-2a36-44bf-8d67-4b2bed13d910"
      },
      "source": [
        "wdbc = pd.read_csv(\"wdbc.data\")\n",
        "wdbc = wdbc.iloc[:,:-1]\n",
        "training,testing = train_test_split(wdbc, test_size=0.3, random_state=42)\n",
        "# training,testing = train_test_split(wdbc, test_size=0.4, random_state=42)\n",
        "# training,testing = train_test_split(wdbc, test_size=0.5, random_state=42)\n",
        "# training,testing = train_test_split(wdbc, test_size=0.2, random_state=42)\n",
        "# training,testing = train_test_split(wdbc, test_size=0.1, random_state=42)\n",
        "\n",
        "train_data = training.iloc[:,1:]\n",
        "test_data = testing.iloc[:,1:]\n",
        "x_train = train_data.iloc[:,1:]\n",
        "x_train = MinMaxScaler().fit_transform(x_train)\n",
        "x_test = test_data.iloc[:,1:]\n",
        "x_test = MinMaxScaler().fit_transform(x_test)\n",
        "\n",
        "# Converting the labelled outcomes into numerical data\n",
        "# Malignant = 0\n",
        "# Benign = 1\n",
        "y_train = train_data.iloc[:,:1]\n",
        "y_train[y_train=='M'] = 0\n",
        "y_train[y_train=='B'] = 1\n",
        "print(\"Training Data :\", y_train.shape)\n",
        "\n",
        "y_test = test_data.iloc[:,:1]\n",
        "y_test[y_test=='M'] = 0\n",
        "y_test[y_test=='B'] = 1\n",
        "print(\"Testing Data :\", y_test.shape)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data : (398, 1)\n",
            "Testing Data : (171, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:2986: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self._where(-key, value, inplace=True)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpNu4plSkL5D",
        "colab_type": "text"
      },
      "source": [
        "**Looking at the Shape of the training and testing data that we have now :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ligg6zVZvFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "db04d73b-14d4-4198-b390-385e8f077a84"
      },
      "source": [
        "print(\"Training Data :\", x_train.shape)\n",
        "print(\"Testing Data :\", x_test.shape)\n",
        "print(\"Training Data :\", y_train.shape)\n",
        "print(\"Testing Data :\", y_test.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data : (398, 30)\n",
            "Testing Data : (171, 30)\n",
            "Training Data : (398, 1)\n",
            "Testing Data : (171, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7mpePKsankG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None,30])\n",
        "y = tf.placeholder(tf.float32, [None, 1])\n",
        "# weight\n",
        "weight = tf.Variable(tf.random_normal([30,1], seed=0), name='weight')\n",
        "\n",
        "# bias\n",
        "bias = tf.Variable(tf.random_normal([1], seed=0), name='bias')\n",
        "logits = tf.matmul(x,weight) + bias\n",
        "\n",
        "layer = tf.nn.sigmoid(logits)\n",
        "# layer = tf.nn.relu(logits)\n",
        "# layer = tf.nn.tanh(logits)\n",
        "\n",
        "exp = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y)\n",
        "cost = tf.reduce_mean(exp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gPkoLI0a4zU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
        "# train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)\n",
        "prediction = tf.cast(layer > 0.5, dtype=tf.float32)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O89V2g_KnYHI",
        "colab_type": "text"
      },
      "source": [
        "**Running the Single Layer Perceptron structure, computed accuracies achieved with different number of steps to do a comparitive analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtqMa_2barmo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "4be15ced-8f0d-466e-ae5d-523a35ef4e01"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # for step in range(5001):\n",
        "    # for step in range(15001):\n",
        "    # for step in range(20001):\n",
        "    for step in range(10001):\n",
        "        sess.run(train, feed_dict={x: x_train, y: y_train})\n",
        "        if step % 1000 == 0:\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: x_train, y: y_train})\n",
        "            print(\"Step Number: {:5}\\tLoss: {:.3f}\\tAccuracy: {:.2%}\".format(step, loss, acc))\n",
        "            \n",
        "    train_accuracy = sess.run(accuracy, feed_dict={x: x_train, y: y_train})\n",
        "    test_accuracy,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={x: x_test, y: y_test})\n",
        "    print(\"\\n\")\n",
        "    print(\"Model Accuracy Achieved = {:.2%}\".format(train_accuracy))\n",
        "    print(\"Test Accuracy Achieved = {:.2%}\".format(test_accuracy))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step Number:     0\tLoss: 0.848\tAccuracy: 39.70%\n",
            "Step Number:  1000\tLoss: 0.238\tAccuracy: 91.21%\n",
            "Step Number:  2000\tLoss: 0.180\tAccuracy: 94.72%\n",
            "Step Number:  3000\tLoss: 0.154\tAccuracy: 96.23%\n",
            "Step Number:  4000\tLoss: 0.138\tAccuracy: 96.98%\n",
            "Step Number:  5000\tLoss: 0.128\tAccuracy: 97.49%\n",
            "Step Number:  6000\tLoss: 0.120\tAccuracy: 97.74%\n",
            "Step Number:  7000\tLoss: 0.114\tAccuracy: 97.99%\n",
            "Step Number:  8000\tLoss: 0.110\tAccuracy: 98.24%\n",
            "Step Number:  9000\tLoss: 0.106\tAccuracy: 98.24%\n",
            "Step Number: 10000\tLoss: 0.102\tAccuracy: 98.24%\n",
            "\n",
            "\n",
            "Model Accuracy Achieved = 98.24%\n",
            "Test Accuracy Achieved = 94.74%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Xl8JsXq__w",
        "colab_type": "text"
      },
      "source": [
        "**The next methods tried is using the same Single Layer Perceptron structure, but applying Principal Component Analysis first. Here various number of components were tested out.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Fx_7-8WdQ3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# comp is the number of PCA Components [passed]\n",
        "comp = 15\n",
        "pca = sklearnPCA(n_components = comp)\n",
        "pca_train_x = pca.fit_transform(x_train)\n",
        "pca_test_x = pca.fit_transform(x_test)\n",
        "x = tf.placeholder(tf.float32, [None,comp])\n",
        "y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "weight = tf.Variable(tf.random_normal([comp,1], seed=0), name='weight')\n",
        "bias = tf.Variable(tf.random_normal([1], seed=0), name='bias')\n",
        "logits = tf.matmul(x,weight) + bias\n",
        "layer = tf.nn.sigmoid(logits)\n",
        "exp = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y)\n",
        "cost = tf.reduce_mean(exp)\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.2).minimize(cost)\n",
        "\n",
        "prediction = tf.cast(layer > 0.5, dtype=tf.float32)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjuAzbTLt2kd",
        "colab_type": "text"
      },
      "source": [
        "**Running the PCA SLP Model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9VmRFNBtt0Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "67b374ed-8b70-47d5-c3ef-c59ce863b399"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(10001):\n",
        "        sess.run(train, feed_dict={x: pca_train_x, y: y_train})\n",
        "        if step % 1000 == 0:\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: pca_train_x, y: y_train})\n",
        "            print(\"Step Number: {:5}\\tLoss: {:.3f}\\tAccuracy: {:.2%}\".format(step, loss, acc))\n",
        "\n",
        "    train_accuracy = sess.run(accuracy, feed_dict={x: pca_train_x, y: y_train})\n",
        "    test_accuracy,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={x: pca_test_x, y: y_test})\n",
        "    \n",
        "print(\"\\n\")\n",
        "print(\"Model Accuracy Achieved = {:.2%}\".format(train_accuracy))\n",
        "print(\"Test Accuracy Achieved = {:.2%}\".format(test_accuracy))\n",
        "        "
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step Number:     0\tLoss: 0.700\tAccuracy: 54.52%\n",
            "Step Number:  1000\tLoss: 0.141\tAccuracy: 95.98%\n",
            "Step Number:  2000\tLoss: 0.116\tAccuracy: 96.98%\n",
            "Step Number:  3000\tLoss: 0.105\tAccuracy: 97.49%\n",
            "Step Number:  4000\tLoss: 0.098\tAccuracy: 97.74%\n",
            "Step Number:  5000\tLoss: 0.094\tAccuracy: 97.74%\n",
            "Step Number:  6000\tLoss: 0.090\tAccuracy: 97.74%\n",
            "Step Number:  7000\tLoss: 0.088\tAccuracy: 97.74%\n",
            "Step Number:  8000\tLoss: 0.085\tAccuracy: 97.99%\n",
            "Step Number:  9000\tLoss: 0.084\tAccuracy: 97.99%\n",
            "Step Number: 10000\tLoss: 0.082\tAccuracy: 97.99%\n",
            "\n",
            "\n",
            "Model Accuracy Achieved = 97.99%\n",
            "Test Accuracy Achieved = 96.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCjl3goIuX2D",
        "colab_type": "text"
      },
      "source": [
        "**Running a Multi Layer Perceptron Structure after Implementing PCA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTgRJ14pdnvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "comp = 5\n",
        "pca = sklearnPCA(n_components=comp)\n",
        "pca_mlp_train_x = pca.fit_transform(x_train)\n",
        "\n",
        "pca_mlp_test_x = pca.fit_transform(x_test)\n",
        "\n",
        "x = tf.placeholder(tf.float32, [None,comp])\n",
        "y = tf.placeholder(tf.float32, [None, 1])\n",
        "\n",
        "# input layer\n",
        "weight1 = tf.Variable(tf.random_normal([comp,64], seed=0), name='weight1')\n",
        "bias1 = tf.Variable(tf.random_normal([64], seed=0), name='bias1')\n",
        "layer1 = tf.nn.sigmoid(tf.matmul(x,weight1) + bias1)\n",
        "\n",
        "weight2 = tf.Variable(tf.random_normal([64,128], seed=0), name='weight2')\n",
        "bias2 = tf.Variable(tf.random_normal([128], seed=0), name='bias2')\n",
        "layer2 = tf.nn.sigmoid(tf.matmul(layer1,weight2) + bias2)\n",
        "weight3 = tf.Variable(tf.random_normal([128,128], seed=0), name='weight3')\n",
        "bias3 = tf.Variable(tf.random_normal([128], seed=0), name='bias3')\n",
        "layer3 = tf.nn.sigmoid(tf.matmul(layer2,weight3) + bias3)\n",
        "\n",
        "# output layer\n",
        "weight4 = tf.Variable(tf.random_normal([128,1], seed=0), name='weight4')\n",
        "bias4 = tf.Variable(tf.random_normal([1], seed=0), name='bias4')\n",
        "logits = tf.matmul(layer3,weight4) + bias4\n",
        "output_layer = tf.nn.sigmoid(logits)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_RbMW7svctM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=y)\n",
        "cost = tf.reduce_mean(exp)\n",
        "train = tf.train.GradientDescentOptimizer(learning_rate=0.005).minimize(cost)\n",
        "\n",
        "prediction = tf.cast(output_layer > 0.5, dtype=tf.float32)\n",
        "correct_prediction = tf.equal(prediction, y)\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rI8IkrSwEv9",
        "colab_type": "text"
      },
      "source": [
        "**Running the PCA MLP Model:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6MEjvqlvhdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "0271986c-1551-4418-d46a-8254f4fcdfa7"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for step in range(10001):\n",
        "        sess.run(train, feed_dict={x: pca_mlp_train_x, y: y_train})\n",
        "        if step % 1000 == 0:\n",
        "            loss, acc = sess.run([cost, accuracy], feed_dict={x: pca_mlp_train_x, y: y_train})\n",
        "            print(\"Step Number: {:5}\\tLoss: {:.3f}\\tAccuracy: {:.2%}\".format(step, loss, acc))\n",
        "\n",
        "    train_accuracy = sess.run(accuracy, feed_dict={x: pca_mlp_train_x, y: y_train})\n",
        "    test_accuracy,test_predict,test_correct = sess.run([accuracy,prediction,correct_prediction], feed_dict={x: pca_mlp_test_x, y: y_test})\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Model Accuracy Achieved = {:.2%}\".format(train_accuracy))\n",
        "print(\"Test Accuracy Achieved = {:.2%}\".format(test_accuracy))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step Number:     0\tLoss: 3.107\tAccuracy: 62.56%\n",
            "Step Number:  1000\tLoss: 0.146\tAccuracy: 96.23%\n",
            "Step Number:  2000\tLoss: 0.113\tAccuracy: 96.48%\n",
            "Step Number:  3000\tLoss: 0.099\tAccuracy: 96.98%\n",
            "Step Number:  4000\tLoss: 0.091\tAccuracy: 97.24%\n",
            "Step Number:  5000\tLoss: 0.085\tAccuracy: 97.24%\n",
            "Step Number:  6000\tLoss: 0.081\tAccuracy: 97.24%\n",
            "Step Number:  7000\tLoss: 0.078\tAccuracy: 97.24%\n",
            "Step Number:  8000\tLoss: 0.076\tAccuracy: 97.49%\n",
            "Step Number:  9000\tLoss: 0.074\tAccuracy: 97.49%\n",
            "Step Number: 10000\tLoss: 0.072\tAccuracy: 97.74%\n",
            "\n",
            "\n",
            "Model Accuracy Achieved = 97.74%\n",
            "Test Accuracy Achieved = 97.08%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83Ry42lmzTLI",
        "colab_type": "text"
      },
      "source": [
        "**Alternative MLP Classification using Keras (Without PCA) (Implementation only for testing)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufzfav6czXyH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eba6ea44-8a68-49a9-af72-9c931b6a0d9e"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=30, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=128)\n",
        "score = model.evaluate(x_test, y_test, batch_size=128)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "398/398 [==============================] - 0s 230us/step - loss: 0.6906 - accuracy: 0.6281\n",
            "Epoch 2/100\n",
            "398/398 [==============================] - 0s 35us/step - loss: 0.7167 - accuracy: 0.5628\n",
            "Epoch 3/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.6483 - accuracy: 0.6457\n",
            "Epoch 4/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.7207 - accuracy: 0.5980\n",
            "Epoch 5/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.6597 - accuracy: 0.6080\n",
            "Epoch 6/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.6713 - accuracy: 0.6080\n",
            "Epoch 7/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.6072 - accuracy: 0.6558\n",
            "Epoch 8/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.6202 - accuracy: 0.6407\n",
            "Epoch 9/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.5716 - accuracy: 0.7312\n",
            "Epoch 10/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.5849 - accuracy: 0.6985\n",
            "Epoch 11/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.5444 - accuracy: 0.7412\n",
            "Epoch 12/100\n",
            "398/398 [==============================] - 0s 28us/step - loss: 0.5286 - accuracy: 0.7513\n",
            "Epoch 13/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.4945 - accuracy: 0.7990\n",
            "Epoch 14/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.5162 - accuracy: 0.7638\n",
            "Epoch 15/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.4870 - accuracy: 0.8040\n",
            "Epoch 16/100\n",
            "398/398 [==============================] - 0s 35us/step - loss: 0.4501 - accuracy: 0.8141\n",
            "Epoch 17/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.4410 - accuracy: 0.8166\n",
            "Epoch 18/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.4236 - accuracy: 0.8417\n",
            "Epoch 19/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.4360 - accuracy: 0.8141\n",
            "Epoch 20/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.3733 - accuracy: 0.8618\n",
            "Epoch 21/100\n",
            "398/398 [==============================] - 0s 30us/step - loss: 0.3727 - accuracy: 0.8492\n",
            "Epoch 22/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.3782 - accuracy: 0.8568\n",
            "Epoch 23/100\n",
            "398/398 [==============================] - 0s 35us/step - loss: 0.3434 - accuracy: 0.8693\n",
            "Epoch 24/100\n",
            "398/398 [==============================] - 0s 39us/step - loss: 0.3886 - accuracy: 0.8266\n",
            "Epoch 25/100\n",
            "398/398 [==============================] - 0s 45us/step - loss: 0.3570 - accuracy: 0.8618\n",
            "Epoch 26/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.3587 - accuracy: 0.8492\n",
            "Epoch 27/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.3227 - accuracy: 0.8769\n",
            "Epoch 28/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.2892 - accuracy: 0.9070\n",
            "Epoch 29/100\n",
            "398/398 [==============================] - 0s 35us/step - loss: 0.3059 - accuracy: 0.8744\n",
            "Epoch 30/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.2844 - accuracy: 0.8970\n",
            "Epoch 31/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.3000 - accuracy: 0.8744\n",
            "Epoch 32/100\n",
            "398/398 [==============================] - 0s 38us/step - loss: 0.2891 - accuracy: 0.8769\n",
            "Epoch 33/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.2936 - accuracy: 0.8719\n",
            "Epoch 34/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.2956 - accuracy: 0.8794\n",
            "Epoch 35/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.3013 - accuracy: 0.8693\n",
            "Epoch 36/100\n",
            "398/398 [==============================] - 0s 43us/step - loss: 0.2886 - accuracy: 0.8894\n",
            "Epoch 37/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.2760 - accuracy: 0.8844\n",
            "Epoch 38/100\n",
            "398/398 [==============================] - 0s 35us/step - loss: 0.2350 - accuracy: 0.9070\n",
            "Epoch 39/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.2546 - accuracy: 0.9020\n",
            "Epoch 40/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.2463 - accuracy: 0.9121\n",
            "Epoch 41/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.2367 - accuracy: 0.9095\n",
            "Epoch 42/100\n",
            "398/398 [==============================] - 0s 27us/step - loss: 0.2409 - accuracy: 0.9070\n",
            "Epoch 43/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.2571 - accuracy: 0.9020\n",
            "Epoch 44/100\n",
            "398/398 [==============================] - 0s 30us/step - loss: 0.2582 - accuracy: 0.9095\n",
            "Epoch 45/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.2253 - accuracy: 0.9070\n",
            "Epoch 46/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.2181 - accuracy: 0.9196\n",
            "Epoch 47/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.2214 - accuracy: 0.9070\n",
            "Epoch 48/100\n",
            "398/398 [==============================] - 0s 39us/step - loss: 0.2297 - accuracy: 0.9171\n",
            "Epoch 49/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.2509 - accuracy: 0.9070\n",
            "Epoch 50/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.2304 - accuracy: 0.9171\n",
            "Epoch 51/100\n",
            "398/398 [==============================] - 0s 54us/step - loss: 0.2099 - accuracy: 0.9221\n",
            "Epoch 52/100\n",
            "398/398 [==============================] - 0s 51us/step - loss: 0.2230 - accuracy: 0.9146\n",
            "Epoch 53/100\n",
            "398/398 [==============================] - 0s 58us/step - loss: 0.2137 - accuracy: 0.9246\n",
            "Epoch 54/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.2139 - accuracy: 0.9171\n",
            "Epoch 55/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.2144 - accuracy: 0.9246\n",
            "Epoch 56/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.2394 - accuracy: 0.9146\n",
            "Epoch 57/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1931 - accuracy: 0.9271\n",
            "Epoch 58/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.2162 - accuracy: 0.9121\n",
            "Epoch 59/100\n",
            "398/398 [==============================] - 0s 50us/step - loss: 0.1901 - accuracy: 0.9221\n",
            "Epoch 60/100\n",
            "398/398 [==============================] - 0s 44us/step - loss: 0.1838 - accuracy: 0.9347\n",
            "Epoch 61/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.1752 - accuracy: 0.9322\n",
            "Epoch 62/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.1890 - accuracy: 0.9246\n",
            "Epoch 63/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1945 - accuracy: 0.9246\n",
            "Epoch 64/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.2015 - accuracy: 0.9171\n",
            "Epoch 65/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.1644 - accuracy: 0.9397\n",
            "Epoch 66/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1830 - accuracy: 0.9447\n",
            "Epoch 67/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1771 - accuracy: 0.9271\n",
            "Epoch 68/100\n",
            "398/398 [==============================] - 0s 46us/step - loss: 0.1960 - accuracy: 0.9271\n",
            "Epoch 69/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.1734 - accuracy: 0.9296\n",
            "Epoch 70/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1850 - accuracy: 0.9296\n",
            "Epoch 71/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.1633 - accuracy: 0.9447\n",
            "Epoch 72/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.1745 - accuracy: 0.9372\n",
            "Epoch 73/100\n",
            "398/398 [==============================] - 0s 42us/step - loss: 0.1613 - accuracy: 0.9422\n",
            "Epoch 74/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.1639 - accuracy: 0.9472\n",
            "Epoch 75/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.1542 - accuracy: 0.9397\n",
            "Epoch 76/100\n",
            "398/398 [==============================] - 0s 34us/step - loss: 0.1747 - accuracy: 0.9372\n",
            "Epoch 77/100\n",
            "398/398 [==============================] - 0s 29us/step - loss: 0.1533 - accuracy: 0.9422\n",
            "Epoch 78/100\n",
            "398/398 [==============================] - 0s 33us/step - loss: 0.1843 - accuracy: 0.9095\n",
            "Epoch 79/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.1513 - accuracy: 0.9372\n",
            "Epoch 80/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.1700 - accuracy: 0.9422\n",
            "Epoch 81/100\n",
            "398/398 [==============================] - 0s 40us/step - loss: 0.1540 - accuracy: 0.9497\n",
            "Epoch 82/100\n",
            "398/398 [==============================] - 0s 42us/step - loss: 0.1703 - accuracy: 0.9347\n",
            "Epoch 83/100\n",
            "398/398 [==============================] - 0s 50us/step - loss: 0.1626 - accuracy: 0.9397\n",
            "Epoch 84/100\n",
            "398/398 [==============================] - 0s 46us/step - loss: 0.1394 - accuracy: 0.9472\n",
            "Epoch 85/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1568 - accuracy: 0.9322\n",
            "Epoch 86/100\n",
            "398/398 [==============================] - 0s 38us/step - loss: 0.1317 - accuracy: 0.9497\n",
            "Epoch 87/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1343 - accuracy: 0.9472\n",
            "Epoch 88/100\n",
            "398/398 [==============================] - 0s 39us/step - loss: 0.1217 - accuracy: 0.9598\n",
            "Epoch 89/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1201 - accuracy: 0.9648\n",
            "Epoch 90/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1362 - accuracy: 0.9548\n",
            "Epoch 91/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1341 - accuracy: 0.9472\n",
            "Epoch 92/100\n",
            "398/398 [==============================] - 0s 36us/step - loss: 0.1104 - accuracy: 0.9598\n",
            "Epoch 93/100\n",
            "398/398 [==============================] - 0s 37us/step - loss: 0.1259 - accuracy: 0.9447\n",
            "Epoch 94/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.1570 - accuracy: 0.9422\n",
            "Epoch 95/100\n",
            "398/398 [==============================] - 0s 44us/step - loss: 0.1419 - accuracy: 0.9372\n",
            "Epoch 96/100\n",
            "398/398 [==============================] - 0s 47us/step - loss: 0.1358 - accuracy: 0.9548\n",
            "Epoch 97/100\n",
            "398/398 [==============================] - 0s 47us/step - loss: 0.1413 - accuracy: 0.9497\n",
            "Epoch 98/100\n",
            "398/398 [==============================] - 0s 30us/step - loss: 0.1238 - accuracy: 0.9548\n",
            "Epoch 99/100\n",
            "398/398 [==============================] - 0s 31us/step - loss: 0.1391 - accuracy: 0.9573\n",
            "Epoch 100/100\n",
            "398/398 [==============================] - 0s 32us/step - loss: 0.1366 - accuracy: 0.9548\n",
            "171/171 [==============================] - 0s 355us/step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}